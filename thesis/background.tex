%% The following is a directive for TeXShop to indicate the main file
%%!TEX root = diss.tex

\chapter{Background}

Perceptual learning is a well established phenomenon in the psychology and psychophysics literature. Training can improve a participants ability to discriminate in many disparate modalities, such as visual acuity, somatosensory spatial resolution, weight estimation, and discrimination of hue and pitch \citep[reviewed in ]{Gibson1953}.  

%\citet{Gibson1953}: "Improvement is arbitrarily defined, then, as closer, more precise, more immediate approximation of \emph{O}'s judgment to the appropriate physical standard or measure" (p403).  Also: "Practice, for the present purposes, will be defined as any controlled activity of \emph{O} which involves repeated perception of the test stimuli or ones similar to them.  This definition assumes attention on the part of \emph{O}, but it deliberately omits any requirement of reinforcement, correction or reward."

Listeners of a language are faced with a large degree of variability when interacting with their fellow language users.  
Speakers can have different sizes, different genders, and different backgrounds that make speech sound categories, at first blush, overlapping in distribution and hard to separate in acoustic domains.
Despite this, listeners maintain a large degree of perceptual constancy, through speaker normalization and perceptual learning.  
Ambiguous vowel sounds can be mapped to different categories depending on the vowels of the preceding context \citep{Ladefoged1957}, where the previously-unheard ambiguous tokens is normalized to the vowel space present in the context.  
Perceptual learning refers to the updating of distributions corresponding to a sound category for a particular speaker.

\section{Perceptual learning}

\citet{Norris2003} began the recent set of investigation into perceptual learning in speech. Previous work has demonstrated perceptual learning in the visual domain (Color hue reference?) and (I think auditory as well).  
\citet{Norris2003} exposed Dutch listeners to a fricative halfway between /s/ and /f/ at the ends of words and nonwords and tested their categorization on a fricative continuum from 100\% /s/ to 100\% /f/. 
 Listeners exposed to the ambiguous fricative at the end of words shifted their categorization behaviour, while those exposed to them at the end of nonwords did not.  The exposure using words was further differentiated by the bias introduced by the words.  
Half the tokens ending in the ambiguous fricative formed a word if the fricative was interpreted as /s/ but not if it was interpreted as /f/, and the others were the reverse.  
Listeners exposed only to the /s/-biased tokens categorized more of the /f/-/s/ continuum as /s/, and listeners exposed to /f/-biased tokens categorized more of the continuum as /f/.  
The ambiguous fricative was associated with either /s/ or /f/ dependent on the bias of the word, which led to an expanded category for that fricative at the expense of the other category.

%\citet{SamuelKraljic2009}

%\citet{Sumner2011}


%\section{Timecourse}

%Mitterer, H., & Reinisch, E. (in press). No delays in application of perceptual learning in speech recognition: Evidence from eye tracking.Journal of Memory and Language.

%\citet{Vroomen2004} \cite{Kleinschmidt2011}

%\citet{Trude2012}

In addition to lexically-guided perceptual learning, unambiguous visual cues to sound identity can cause perceptual learning as well (referred to as perceptual recalibration in that literature).
In \citet{Bertelson2003}, an auditory continuum from /aba/ to /ada/ was synthesized and paired with a video of a speaker producing /aba/ and a video of /ada/.  
Participants first completed a pretest that identified the maximally ambiguous step of the /aba/-/ada/ auditory continuum. 
 In eight blocks, participants were randomly exposed to the ambiguous auditory token paired with video for /aba/ or with the video for /ada/.  Following each block, they completed a short categorization test.  
These categorization tests showed clear perceptual recalibration effects, such that the participant was more likely to respond with /aba/ if they had been exposed to video of /aba/ paired with the ambiguous token in the preceding block, and likewise for /ada/.

\citet{vanLinden2007} compared the perceptual recalibration effects from the visual lipread paradigm \citep{Bertelson2003} to the standard lexically-guided perceptual learning paradigm \citep{Norris2003}.  
Lipread recalibration and perceptual learning effects had comparable size, lasted equally as long, were enhanced when presented with a contrasting sound, and were both unaffected by periods of silence between exposure and categorization.  
The effects did not last through prolonged testing in this study, unlike in other studies \citep{Kraljic2005,Eisner2006}.


\section{Retention}
\label{sec:retention}

\citet{Kraljic2005} looked at the strength of the perceptual learning effect across various types of unlearning tasks. 
 Native English listeners were exposed to ambiguous fricatives in between /s/ and /\textesh/ in words that biased interpretation toward either /s/ or /\textesh/ in a lexical decision task either spoken by a female voice or a male voice.
 Participants that completed an /s/-/\textesh/ categorization task immediately following exposure and also those that had a 25 minute visua Unlearning task between exposure and categorization showed a large perceptual learning effect.  
Additionally, participants that had an Unlearning task involving auditory input from the same speaker as they were exposed to showed attenuated perceptual learning effects when the speech contained correct versions of the ambiguous fricatives, i.e. correct /s/ tokens when they were exposed to the ambiguous sibilant in all /s/ words in the exposure task.  
The perceptual learning effect in this condition was almost eliminated. 
 Participants that had an Unlearning task involving auditory input that did not have any /s/ or /\textesh/ tokens showed perceptual learning effects comparable to those with no Unlearning task.  
When the Unlearning task involved auditory input from a different speaker than exposure, perceptual learning effects were as robust as when there was no Unlearning task.

\citet{Eisner2006} looked at the stability of perceptual learning. 
Dutch participants first completed a categorization task for a continuum of /s/ to /f/ and then listened to a story that contained ambiguous fricative between /s/ and /f/, with one version having the ambiguous fricative in /s/ contexts and the other having it in /f/ contexts.
Immediately following, they completed another /s/ to /f/ categorization task.  
Finally, 12 hours later, they completed the categorization task once again.
Half the participants started at 9 am and completed the final categorization task at 9 pm the same day, and the other half started at 9 pm and completed the final categorization at 9 am the following day.
Perceptual learning effects were found in both categorization tasks following exposure, with no significant differences between the two times. 
 The perceptual learning effects found were robust across time and across intervening language exposure, as the those tested at 9 am and 9 pm likely had many interactions with other people in between.

Perceptual learning effects are robust across time.  
Given no other interactions with a given speaker, a listener's behaviour for that speaker's speech will remain constant over the course of a day, and probably longer. 
However, the perceptual system remains plastic.  
If a listener is exposed to a speaker trait in the first interaction, but the trait disappears in later interactions, the perceptual system will reattenuate to the newer evidence.

\section{Generalization}

\subsection{Generalizing to new speakers}

\citet{Kraljic2007} looked at different sound contrasts and the ability of participants to generalize across speakers.  
The first contrast was voicing between /t/ and /d/.  
When exposed to ambiguous stops between /t/ and /d/ corresponding to /d/ for one speaker, and ambiguous stops correpsonding to /t/ for another, perceptual learning effects corresponded to the most recent exposure, regardless of whether the test voice was the same as that recent exposure voice.  
The second contrast they used was sibilants of /s/ and /\textesh/. 
 For this contrast, they found the speaker-specificity effect found in the literature, where recency of the exposure did not affect the perceptual learning for a particular voice.  They argue that the differences between these two contrasts lies in the relative indexical information carried by the sibilants and the lack of much indexical information carried in the stops.

\citet{Eisner2005} looked at what manipulations could cause perceptual learning could generalize to additional talkers.  
Using a Dutch lexical decision task with ambiguous fricatives in between /s/ and /f/, they tested categorization on a contniuum between /s/ and /f/ from two talkers.  
When exposed to one talker's ambiguous fricative and tested on another speaker's continuum, no perceptual learning effect was found.  
There were two conditions where the fricatives in the exposure and categorization came from the same speaker, but the speakers of the carrier speech.  
In one, the ambiguous fricative from the categorization speaker's produtions was spliced into the exposure tokens, and in the other, the exposure talker's /s/ to /f/ continuum were spliced with vowels from the categorization talker.
In these two conditions, they did find a perceptual learning effect across speakers, despite reports by the participants of hearing different speakers, suggesting a sound-specificity effect in addition (or potentially causing) speaker-specificity effects. 

\citet{Reinisch2013} looked at perceptual learning of speaker characteristics across languages.  
When exposed to a native Dutch speaker speaking English with ambiguous fricatives between /s/ and /f/, participants show a perceptual learning effect when categorizing Dutch minimal pairs differing only in whether one sound is an /f/ or /s/ spoken by the same speaker.  
When exposed to the same native Dutch speaker speaking Dutch words and nonwords with the same ambiguous fricative, native Dutch listeners and L2 Dutch listeners (native German speakers) show comparable perceptual learning effects.

\citet{Reinisch2013a} Holt exposed native English listeners to a female Dutch-accented voice speaking words and nonwords, where words ending in /s/ or /f/ instead ended either in a natural token or an ambiguous fricative between /s/ and /f/.  
Listeners showed a perceptual learning effect for the exposure talker as well as another female Dutch-accented voice, showing cross-speaker generalization.  
However, when categorizing a continuum from /s/ to /f/ of a male Dutch-accented voice, listeners did not generalize the perceptual learning effect, but there was a slight perceptual learning effect for the first block of categorization tokens for the male voice that disappeared in later blocks.  
Pretests of the continua revealed that the male voice continuum was heavily biased towards /s/, with steps 1-4 of the continuum consistently heard as /s/. 
 For the exposure female voice, Steps 1-4 were already ambiguous between /s/ and /f/, with the proportion /s/ response less than 60\% for all steps.  
The new female voice was responded to similar to the exposure female voice, but with less ambiguity for the initial step.  
When the continua for the exposure female voice and the male voice were more closely matched by removing the first four steps of the male voice and removing 4 steps along the continuum of the female voice, generalization of the perceptual learning effects matched those for the new female voice.  
These findings suggest that the perceptual system leverages known distributions that may not be speaker specific.  
When new tokens fall outside that known distribution, as in the male voice categorization, perceptual learning for that voice occurred using the relatively abundant unambiguous examples for that speaker to adjust the perceptual system for that talker.

\citet{Kraljic2005}, in addition to the findings reported in in Section~\ref{sec:retention}, also found an asymmetry in how listeners generalized perceptual learning.  
Across all of their experiments, categorization of the same voice as exposure produced perceptual learning.  
When the continuum from /s/ to /\textesh/ from the male voice was categorized following exposure to the female voice, perceptual learning effects were consistently present.
When the voice of the exposure and categorization was reversed, the consistency of perceptual learning effects disappeared. 
They performed an acoustic analysis of the spectral means for the categorization items and the exposure items for each talker.  The spectral means of the voices for the continuum steps were well separated, but the exposure items were much closer together.  The spectral mean of the ambiguous sibilant for the female voice fell in between the ranges of the female continuum steps and the male continuum steps, but the spectral mean exposure ambiguous sibilant for the male voice was squarely in the range of the male continuum steps.  The asymmetry of speaker generalization can then be attributed to the female exposure ambiguous items being acoustically (and therefore perceptually) similar enough to generalize the perceptual learning for the female voice to the male voice.

From these studies, the clearest thread through all of them is the degree of acoustic similarity or perceptual similarity between the exposure stimuli that prompts perceptual learning and whatever continuum the listeners are tested on.  
Stops and fricative do not actually appear to behave categorically different, per se, but their differences in behaviour can be attributed to the fact that stops are acoustically more similar to each other in general than fricatives are.

\subsection{Generalizing to other categories and contexts}

\citet{Kraljic2006} looked at two sound contrasts (/d/-/t/ and /b/-/p/) that shared a feature, namely voicing.  
Participants were exposed to ambiguous in between /d/ and /t/ in English words and then tested on two continua with two different voices.  
The categorization continuum that was presented first, from /b/ to /p/, showed the stronger perceptual learning effects than the second continuum from /d/ to /t/, even though participants were exposed to ambiguous tokens between /d/ and /t/. 
 Both old voices and new voices for the categorization task produced perceptual learning effects.

\citet{Mitterer2013} exposed participants to either words ending with /r/ or /l/ or to words beginning with /r/ or /l/, and tested each group's perceptual learning behaviour on continua from /r/ to /l/ in both initial and final positions.  
If listeners were exposed to an ambiguous sound between /r/ and /l/ at the ends of words, they showed a perceptual learning effect for the continuum that ended with an /r/ or /l/, but not for the continuum that began with an /r/ or an /l/.  
The inverse behaviour was observed for the group that was exposed to an ambiguous sound between /r/ and /l/ at the beginnings of words.  
They argue that the category being affected is not a context-insensitive phoneme, but rather a context sensitive allophone.  
\citet{Jesse2011} found that listeners did indeed generalize across positions, but their stimuli were the fricatives /s/ and /f/, and the same physical fricatives were the same across all positions.

%\citet{Clare2014}

\citet{Reinisch2014} utilized a visually-guided recalibration paradigm from \citet{Bertelson2003} to test whether acoustic cues to place of articulation could be recalibrated with unambiguous visual feedback.  
In Experiment 1, they trained listeners by exposing one group to the maximally ambiguous token between /aba/ and /ada/ with either a video of /ada/ or /aba/ and another group to the maximally ambiguous token between /ibi/ and /idi/ with either a video of /ibi/ or /idi/.  
In vowel context of /a/, the consonant portion of the token was silenced so that only formant cues to place of articulation would be available.  
In the vowel context of /i/, the consonant part was not silenced, but since formant transitions in the /i/ context are the same for labials and dentals, the only cues to place of articulation would be in the consonant itself.  
Afterwards, when they categorized auditory only continua of /aba/ to /ada/ and /ibi/ to /idi/ with the same silencing of the consonant in the /a/ context.  They found a recalibration effect for the continuum participants were exposed to, but no generalization effect to the novel continuum.  
Experiment 2 followed the same setup as Experiment 1, with the same /aba/ to /ada/ as in Experiment 1, but replaced the /ibi/ to /idi/ continuum with a /ama/ to /ana/ continuum.  
As in Experiment 1, clear recalibration effects were found for the continuum participants were exposed to, but not for the novel continuum.  
Experiment 3 followed the same procedure but used a /ubu/ to /udu/ continuum instead of an /ibi/ to /idi/ continuum.  
The /u/ context provides formant transition cues to place of articulation, so the consonant was silenced for this continuum as well.  
As before, there were perceptual recalibration effects for the continuum participants were exposed to, but not to the novel continuum.  
Across all of these, there is a context specifity effect. 

\citet{Kraljic2008a} exposed participants to ambiguous sibilants between /s/ and /\textesh/ in two different contexts.  
In one, the ambiguous sibilants were intervocalic, and in the other, they occurred as part of a /str/ cluster.  
Participants exposed to the ambiguous sound intervocalically showed a perceptual learning effect, while those exposed to the sibilants in /str/ environments did not.  
The sibilant in /str/ often surfaces closer to [\textesh] in many varieties of English, due to coarticulatory effects from the other consonants in the cluster, but the coarticulatory effects for merging /s/ and /\textesh/ are much weaker in intervocalic position.  
They argue that the interpretation of the ambiguous sound is done in context of the surrounding sounds, and only when the pronunciation variant is unexplainable from context is the variant learned and attributed to the speaker, see also \citet{Kraljic2008}.  
In addition to a continuum of /asi/ to /a\textesh i/, they also tested a continuum from /astri/ to /a\textesh tri/, and found comparable perceptual learning effects across both continua for those exposed to the intervocalic ambiguous sibilants, but no perceptual learning effects on either continua for the other condition, showing a context insentivity absent in other studies.

\section{Current contribution}

Perceptual learning effects require two important aspects to be involved in the exposure phase.  
There must be some ambiguous acoustic aspect to be learned, and there must be an unambiguous link between the ambiguous acoustics and a sound category. 
This link can be provided through bottom-up information, such as in the visual domain \citep{Bertelson2003}, or it can be top-down information, such as the lexical status of the tokens \citep{Norris2003}. 
Most of the literature within the domain of lexically-guided perceptual learning has been on the presence or absence of perceptual learning in the categorization phases, with manipulations to the categorization phase to test for generalization.  
The question that I am interested in is in the linking of ambiguous tokens to sound categories.  
Can manipulations in the exposure phase that reduce the reliability of the linking cause significant differences in perceptual learning?

In this dissertation,  I will induce manipulations of lexical bias and attention in Experiments 1 and 2, and manipulations of sentence predictability and attention in Experiment 3. 
Lexical bias has been shown to affect phoneme categorization tasks \citep{Ganong1980}, and can be manipulated by position of the ambiguous sound in the word and attention \cite{Pitt2012}.  
Sentence predictability, has likewise been found to affect phoneme categorization tasks similar to lexical bias \citep{Borsky1998}, and can be manipulated by the preceding words in the sentence \citep{Kalikow1977}.  
The interaction of sentence predictability with attention has not been explicitly studied, but the interaction should be similar to lexical bias.
