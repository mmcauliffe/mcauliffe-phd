\subsection{Generalization}
\label{sec:generalization}

\subsubsection{Generalizing to new speakers}
\label{sec:speakergeneralization}

\citet{Kraljic2007} looked at different sound contrasts and the ability of participants to generalize across speakers.  
The first contrast was voicing between /t/ and /d/.  
When exposed to ambiguous stops between /t/ and /d/ corresponding to /d/ for one speaker, and ambiguous stops correpsonding to /t/ for another, perceptual learning effects corresponded to the most recent exposure, regardless of whether the test voice was the same as that recent exposure voice.  
The second contrast they used was sibilants of /s/ and /\textesh/. 
For this contrast, they found the speaker-specificity effect found in the literature, where recency of the exposure did not affect the perceptual learning for a particular voice.
They argue that the differences between these two contrasts lies in the relative indexical information carried by the sibilants and the lack of much indexical information carried in the stops.
Voicing contrasts in onset position are delimited clearly along the voice-onset time dimension, with variability between native English speakers producing little ambiguity between /t/ and /d/.
Sibilant productions can vary dramatically, however.
For instance, male speakers of English produce /s/ and /\textesh/ with spectral means lower than female speakers of English, with overlapping distributions between male /s/ productions and female /\textesh/ productions, and continua of synthetic sibilants are categorized differently depending on the gender of the speaker who produced the rest of the word \citep{Strand1996}.  

\citet{Eisner2005} looked at what manipulations could cause perceptual learning to generalize to additional talkers.  
Using a Dutch lexical decision task with ambiguous fricatives in between /s/ and /f/, they tested categorization on a contniuum between /s/ and /f/ from two talkers.  
When exposed to one talker's ambiguous fricative and tested on another speaker's continuum, no perceptual learning effect was found.  
There were two conditions where the fricatives in the exposure and categorization came from the same speaker, but the speakers of the carrier speech differed.  
In one, the ambiguous fricative from the categorization speaker's produtions was spliced into the exposure tokens, and in the other, the exposure talker's /s/ to /f/ continuum were spliced with vowels from the categorization talker.
In these two conditions, they did find a perceptual learning effect across speakers, despite reports by the participants of hearing different speakers, suggesting a sound-specificity effect in addition (or potentially causing) speaker-specificity effects. 

\citet{Reinisch2013} looked at perceptual learning of speaker characteristics across languages.  
When exposed to a native Dutch speaker speaking English with ambiguous fricatives between /s/ and /f/, participants show a perceptual learning effect when categorizing Dutch minimal pairs differing only in whether one sound is an /f/ or /s/ spoken by the same speaker.  
When exposed to the same native Dutch speaker speaking Dutch words and nonwords with the same ambiguous fricative, native Dutch listeners and L2 Dutch listeners (native German speakers) show comparable perceptual learning effects.

\citet{Reinisch2013a} exposed native English listeners to a female Dutch-accented voice speaking words and nonwords, where words ending in /s/ or /f/ instead ended either in a natural token or an ambiguous fricative between /s/ and /f/.  
Listeners showed a perceptual learning effect for the exposure talker as well as another female Dutch-accented voice, showing cross-speaker generalization.  
However, when categorizing a continuum from /s/ to /f/ of a male Dutch-accented voice, listeners did not generalize the perceptual learning effect, but there was a slight perceptual learning effect for the first block of categorization tokens for the male voice that disappeared in later blocks.  
Pretests of the continua revealed that the male voice continuum was heavily biased towards /s/, with steps 1-4 of the continuum consistently heard as /s/. 
For the exposure female voice, Steps 1-4 were already ambiguous between /s/ and /f/, with the proportion /s/ response less than 60\% for all steps.  
The new female voice was responded to similar to the exposure female voice, but with less ambiguity for the initial step.  
When the continua for the exposure female voice and the male voice were more closely matched by removing the first four steps of the male voice and removing 4 steps along the continuum of the female voice, generalization of the perceptual learning effects matched those for the new female voice.  
These findings suggest that the perceptual system leverages known distributions that may not be speaker specific.  
When new tokens fall outside that known distribution, as in the male voice categorization, perceptual learning for that voice occurred using the relatively abundant unambiguous examples for that speaker to adjust the perceptual system for that talker.

\citet{Kraljic2005}, in addition to the findings reported in in Section~\ref{sec:retention}, also found an asymmetry in how listeners generalized perceptual learning.  
Across all of their experiments, categorization of the same voice as exposure produced perceptual learning.  
When the continuum from /s/ to /\textesh/ from the male voice was categorized following exposure to the female voice, perceptual learning effects were consistently present.
When the voice of the exposure and categorization was reversed, the consistency of perceptual learning effects disappeared. 
They performed an acoustic analysis of the spectral means for the categorization items and the exposure items for each talker.  
The spectral means of the voices for the continuum steps were well separated, but the exposure items were much closer together.  
The spectral mean of the ambiguous sibilant for the female voice fell in between the ranges of the female continuum steps and the male continuum steps, but the spectral mean exposure ambiguous sibilant for the male voice was squarely in the range of the male continuum steps.  
The asymmetry of speaker generalization can then be attributed to the female exposure ambiguous items being acoustically (and therefore perceptually) similar enough to generalize the perceptual learning for the female voice to the male voice.

From these studies, the clearest thread through all of them is the degree of acoustic similarity or perceptual similarity between the exposure stimuli that prompts perceptual learning and whatever continuum the listeners are tested on.  
Stops and fricative do not actually appear to behave categorically different, per se, but their differences in behaviour can be attributed to the fact that stops are acoustically more similar to each other in general than fricatives are.

\subsubsection{Generalizing to other categories and contexts}
\label{sec:othergeneralization}

\citet{Kraljic2006} looked at two sound contrasts (/d/-/t/ and /b/-/p/) that shared a feature, namely voicing.  
Participants were exposed to an ambiguous coronal stop in between /d/ and /t/ in English words and then tested on two continua with two different voices.  
The categorization continuum that was presented first, from /b/ to /p/, showed the stronger perceptual learning effects than the second continuum from /d/ to /t/, even though participants were exposed to ambiguous tokens between /d/ and /t/. 
 Both old voices and new voices for the categorization task produced perceptual learning effects.

\citet{Mitterer2013} exposed participants to either words ending with /r/ or /l/ or to words beginning with /r/ or /l/ in Dutch, and tested each group's perceptual learning behaviour on continua from /r/ to /l/ in both initial and final positions.  
If listeners were exposed to an ambiguous sound between /r/ and /l/ at the ends of words, they showed a perceptual learning effect for the continuum that ended with an /r/ or /l/, but not for the continuum that began with an /r/ or an /l/.  
The inverse behaviour was observed for the group that was exposed to an ambiguous sound between /r/ and /l/ at the beginnings of words.  
They argue that the category being affected is not a context-insensitive phoneme, but rather a context sensitive allophone.  
\citet{Jesse2011} found that listeners did indeed generalize across positions, but their stimuli were the fricatives /s/ and /f/, and the same physical fricatives were the same across all positions.

%\citet{Clare2014}

\citet{Reinisch2014} utilized a visually-guided recalibration paradigm from \citet{Bertelson2003} to test whether acoustic cues to place of articulation could be recalibrated with unambiguous visual feedback.  
In Experiment 1, they trained listeners by exposing one group to the maximally ambiguous token between /aba/ and /ada/ with either a video of /ada/ or /aba/ and another group to the maximally ambiguous token between /ibi/ and /idi/ with either a video of /ibi/ or /idi/.  
In vowel context of /a/, the consonant portion of the token was silenced so that only formant cues to place of articulation would be available.  
In the vowel context of /i/, the consonant part was not silenced, but since formant transitions in the /i/ context are the same for labials and dentals, the only cues to place of articulation would be in the consonant itself.  
Afterwards, when they categorized auditory only continua of /aba/ to /ada/ and /ibi/ to /idi/ with the same silencing of the consonant in the /a/ context.  They found a recalibration effect for the continuum participants were exposed to, but no generalization effect to the novel continuum.  
Experiment 2 followed the same setup as Experiment 1, with the same /aba/ to /ada/ as in Experiment 1, but replaced the /ibi/ to /idi/ continuum with a /ama/ to /ana/ continuum.  
As in Experiment 1, clear recalibration effects were found for the continuum participants were exposed to, but not for the novel continuum.  
Experiment 3 followed the same procedure but used a /ubu/ to /udu/ continuum instead of an /ibi/ to /idi/ continuum.  
The /u/ context provides formant transition cues to place of articulation, so the consonant was silenced for this continuum as well.  
As before, there were perceptual recalibration effects for the continuum participants were exposed to, but not to the novel continuum.  
Across all of these, there is a context specifity effect. 

Attention


In the auditory domain, similar asymmetries have been found between global and local processing.
In \citet{Sussman2002}, participants were presented with three types of tones in different orders, with one second stimulus onset asynchrony (SOA).  
The order of the tones were either random, with tone 1 more frequent than tone 2, which in turn was more than tone 3, or the order of the tones had a general pattern of five tones (1 1 1 1 2).  
They looked at event-related potentials (ERPs) following tone 2, specifically focusing on the mismatch negativity (MMN) ERP and the N2b ERP, which is evoked when a stimulus is attentively detected as being different from regular stimuli.
In addition to the two patterns, there were three attentional conditions.  
In one, participants were instructed to ignore the auditory stimuli and read a book.  
In the second, participants were instructed to listen to the tone pitch and press a key when they heard the lowest pitch one (tone 3). 
 In the final condition, participants were told of the five tone pattern and instructed to respond when one of the tones was replaced by the lowest tone.
When participants were ignoring the auditory stimuli, there was a MMN response following tone 2.  
When attending to the pitch of the tones, regardless of the tone pattern, there was both a MMN response and an N2b response following tone 2.  
When participants attended to the pattern, there was neither a MMN response nor an N2b response after tone 2.
These results suggest that auditory representations can be manipulated by attention, resulting in processing differences.

However, attention can only modulate the representation to the degree that the acoustics allow.
In other similar studies with different stimulus onset asynchronies, patterns were detected more readily.
At a fast presentation rate (100-ms SOA), no MMN was present, even when participants were told to ignore the auditory stimuli \citep{Sussman1998}.
The fast presentation rate is more conducive to chunking the incoming stream into a pattern, whereas the slow presentation rate allows for the participants to process each tone in isolation or as part of a bigger pattern.
Similar results were found for varying SOA in an auditory streaming task \citep{Sussman1998,Sussman1998a}.

Lexical bias


Studies looking at lexical bias generally use a phoneme categorization task, where participants identify a sound at the beginning or end of a word from two possible options that vary in one dimension.  
For instance, given a continuum from /t/ to /d/, participants are asked to identify the sound at the beginning or end as either /t/ or /d/. 
Lexical bias effects are calculated based on two continua, where words are formed at opposite ends. 
For the /t/ to /d/ continua, one would form a word at the /t/ end, such as \emph{task} and one would form a word at the other end, such as \emph{dash}.  
Lexical bias effects are then calculated from the different categorization behaviour for these two continua.

\citet{Connine1987a} established different reaction time profiles for ``perceptual'' and ``postperceptual'' processes in categorizing a continuum.  With lexical bias, response times to the end points of a /d/ to /t/ continuum show no difference whether the continuum forms a word at one end point (such as \emph{dice} to \emph{tice}) or at the other (such as \emph{dype} to \emph{type}).  However, at the boundary between /d/ and /t/, reaction times are faster when a subject responds consistent to the bias (i.e. interprets an ambiguous word \emph{?ice} as \emph{dice}).  For postperceptual processes, in this case a monetary payoff for responding either /d/ or /t/ along a continuum that has nonwords at both ends, the pattern is reversed, where reaction times were faster for responses consistent with the monetary bias at the end points of the continuum, but no such difference was found for the category boundary.  Both biases produced similar categorization patterns, such that the participants biased toward /d/, either lexically or monetarily, categorized more of the continuum as /d/, so the principle difference between the two biases was in the reaction time profile.



In speech production, higher semantic predictability has been found to result in acoustically reduced word tokens.  
In \citet{Scarborough2010}, words produced in highly predictable frames tend to be shorter in duration and have less dispersed vowel realizations.  
This semantic predictability effect did not interact with neighbourhood density, a lexical factor that proxies for the amount of lexical competition a word has.  
Words with many neighbours, and therefore less lexical predictability, had longer durations and more dispersed vowel realizations.  
For both the lexical and the semantic predictability, high predictability led to less distinct word realizations, and low predictability led to more distinct word realizations, independently of each other.
In a study looking at semantic predictability across dialects, \citet{Clopper2008} found that not all dialects realize the effects of semantic predictability the same.  
For the Southern dialect of American English, the results were much the same as in \citet{Scarborough2010}, showing temporal and spectral reduction in high predictabilty environments.  
However, speakers in the Midland dialect showed no such effect, and speakers of the Northern dialect showed more extreme Northen Cities shifting in the the high predictability environment.



Studies looking at perceptual adaptation to nonnative accents have used exposure tasks that incorporate linguistic information beyond the lexical domain.  
For instance, \citet{Clarke2004} and \citet{Bradlow2008} trained listeners on foreign-accented English using sentence exposure items, and \citet{Trude2013} trained listeners on a merger of /i/ and /\textsci/ in French-accented English using a multi-sentence story.
In these studies, while the amount of linguistic information available is greater, so too are the number of characteristics that need to be learned, if the listener does not already have training or experience with the specific non-native accent.



The results of these experiments are contextualized in the existing perceptual learning literature and in models of perceptual learning.
Section~\ref{sec:perceptuallearning} reviews the perceptual learning literature in greater depth, as well as conceptual models that have been proposed for it \citep{Clark2013, Kleinschmidt2011}.
Broadly speaking, perceptual learning is well accounted for by a Bayesian model, where differences between expectations and observed input cause an error signal which updates future expectations, leading to perceptual learning.
The results of the experiments in this dissertation support a more nuanced attention mechanism, however, than that proposed in \citet{Clark2013}.
The mechanism for attention proposed by Clark is gain-based such that increased attention increases the weight of error signals.
Thus, increased attention should lead to increased perceptual learning.
Generalization of perceptual learning, however, is dependent on the task and the attentional set being employed.
An expanded attention mechanism is therefore proposed to unify the results of perceptual learning studies across the psychophysics and speech perception literatures, encompassing the results of the current experiments.
The proposed mechanism inhibits error propagation beyond the level where attention is directed.  
In a perception-oriented attentional set, perceptual learning is hypothesized to occur at the initial perception where encoding is more fine-grained, inhibiting generalization.  
Comprehension-oriented attentional sets are predicted to allow for greater error propagation and abstraction, leading to greater levels of generalization.