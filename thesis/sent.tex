%% The following is a directive for TeXShop to indicate the main file
%%!TEX root = diss.tex

\chapter{Cross-modal word identification}
\label{chap:sent}

%This chapter investigates perceptual learning with a different bias than lexical, by using sentential context to bias participants towards a particular word.

\section{Motivation}

The largest perceptual learning effect was found in Experiment 1 in the No Attention/Word-medial condition, which is the condition that was the least likely to promote a perception-oriented attentional set in listeners.
As the lexical decision task is oriented towards comprehension, those in the No Attention/Word-medial group would have maintained a comprehension-oriented attentional set. 
The experiment in this chapter examines perceptual learning in larger sentence contexts, as opposed to lexically guided perceptual learning in single word paradigms.
 Using sentences ending with final target words containing a modified /s/ category, semantic predictability is used in conjunction with lexical bias to boost linguistic expectations.
Words that are highly predictable from context generate greater linguistic biases for the word.

For our purposes, semantic predictability refers to how predictable the final word in a sentence is \citep{Kalikow1977}.
In general, high predictability sentences contain less signal information, but are easier to process and understand.
For example, semantic predictability in production studies is associated with reduction independent of lexical factors like frequency and neighbourhood density \citep{Scarborough2010, Clopper2008}.  
In speech perception work, semantic predictability and lexical bias been found to have similar effects on phoneme categorization \citep{Connine1987,Borsky1998}.
Sentences with higher semantic predictability are more intelligible in noise, particularly for native speakers \citep[and others]{Kalikow1977, Mayo1997, Fallon2002, Bradlow2007}.
In phoneme restoration tasks, semantic predictability increases the bias to respond that a word is intact and listeners also show sensitivity to noise addition versus noise replacement for semantically predictable words \citep{Samuel1981}.

\citet{Samuel1981} proposes that high predictability sentences are lower cognitive load (i.e. easier to process).  
The lower cognitive load allows for more attentional resources to be allocated to the primary perception-oriented task, resulting in greater perceptual sensitivity.
\citet{Mattys2011} manipulated cognitive load through easier or harder concurrent visual search tasks during a phoneme categorization task.
Mirroring the phoneme restoration results, Mattys and colleagues found greater perceptual sensitivity in conditions with lower cognitive load.
In both of these cases, the goal of the listener was perception-oriented.
Lower cognitive load may free attentional resources which are then allocated to the task at hand.
In a comprehension-oriented task, lower cognitive load would not necessarily always result in greater perceptual sensitivity. 
If a listener's end goal is not perception of a speech sound, then performance on the task would not necessarily be increased by attending further to perception.

There are many possible outcomes for perceptual learning in this experiment.
Many theoretical frameworks do not make explicit predictions about how the perceptual system will be updated in the context of full sentences.
What happens to the perceptual system after that endorsement?
Are the auditory tokens encoded as faithfully for sentences as for words in isolation?
Even if these tokens are encoded, are they reliable enough evidence for perceptual learning?
The experiment reported here takes a first pass at answer some of these questions and sets the stage for future inquiry. 

One promising avenue for exploring this chapter's research questions lies in the reliability of evidence, which has been shown previously to be crucial for perceptual learning \citep{Kraljic2008, Kraljic2008a}.
If ambiguous productions are accompanied by a video of the speaker holding a pen in their mouth, then no perceptual learning is observed \citep{Kraljic2008}.
Likewise, if listeners are first exposed to typical tokens, and then exposed to atypical tokens, no perceptual learning is observed.
If the order is flipped (atypical tokens first), then perceptual learning effects are present \citep{Kraljic2008}.
If there is linguistic context that conditions greater variability, such as for /s/ in /str/ clusters, then modified tokens in those contexts will not cause perceptual learning \citep{Kraljic2008a}.
Kraljic and colleagues argue from these studies that listeners will attribute variation to the context as much as possible, and only fall back to updating perceptual categories when no other explanation is available.
Extending that argument beyond single words, reliability can be thought of in terms of perceived carefulness of a word production.
In an experimental setting, every stimulus is carefully curated by the experimenter.
However, both in the laboratory and outside, words in isolation are produced longer and more clearly than their counterparts in full sentences.
Words in isolated sentences are going to be produced less clearly than words in isolation (though not necessarily unintelligibly).
Words in spontaneous conversation are likely to be the least clear, as seen in the ``massive reduction'' in the Buckeye corpus \citep{Johnson2004, Dilts2013}.
All of these factors are dependent on aspects of the sentence (focus, clause type, etc) or of the speech style, so words in casual conversation will be less clear than words in a formal presentation.

From a perception standpoint, the more clear an acoustic token, the more signal information will be processed.
A listener would view tokens that were produced more clearly, or with great care, as more reliable tokens for that speaker.
Extending the argument by Kraljic and colleagues would predict that sentences should have less perceptual learning than words in isolation because (some of) the variability of a word's production in a sentence can be attributed to the fact that the item is in a sentence context.
Additionally, given the propensity for acoustic reduction in high predictability contexts \citep{Scarborough2010}, words in predictable sentences would be even less reliable and show less perceptual learning.

This all not to say that sentences will always be less effective in driving perceptual learning than words in isolation.
From the literature on perceptual learning of foreign accents, sentences are extremely useful in learning to perceive accented speakers \citep{Bradlow2008}.
For the purposes of learning an accent, sentences are probably better than words in isolation, as the greater context would allow for better identification of the words.
Differences in perceptual learning from native and nonnative speakers can also be seen in the contradictory findings of \citet{Sumner2011} and \citet{Kraljic2008}.
\citet{Sumner2011} found that listeners could update their perceptual categories constantly over the course of the experiment.
In contrast, \citet{Kraljic2008} found that listeners adapted to the first instances of the category that they heard and did not use subsequent tokens.
Unlearning effects in \citet{Kraljic2005} suggest that this might be asymmetric.
That is, listeners may be biased towards their initial expectations for a category of native speakers in ways that they are not for nonnative speakers.

This dissertation largely adopts the predictive coding framework presented in \citet{Clark2013} to account for perceptual learning.
Reliability of sensory information is not directly addressed in Clark's exposition.
The basic form of his model, however, predicts that increasing expectations should always increase error signals.
In one paper cited in \citet{Clark2013}, participants who were expecting to see a face in static had equally-sized neuronal responses in the fusiform face area for face stimuli as for non-face stimuli.  
Participants who were not expecting to see faces showed neuronal responses in that area only for the face stimuli \citep{Egner2010}.
Without any reliability weighting or attribution of error signals, the predictive coding framework would predict larger perceptual learning effects for participants exposed to the modified category in higher predictability sentences.

\section{Methodology}

\subsection{Participants}

A total of 137 participants from the UBC population completed the experiment and were compensated with either \$10 CAD or course credit.  
The data from 39 non-native speakers of English were excluded from the analyses.
No participants reported speech or hearing disorders.
This left data from 98 participants for analysis.
Twenty additional native English speakers participated in a pretest to determine sentence predictability, and 10 other native English speakers participated in a picture naming pretest.

\subsection{Materials}

One hundred and twenty sentences were used as exposure materials.  
The set of sentences consisted of 40 critical sentences, 20 control sentences and 60 filler sentences. 
The critical sentences ended in one of 20 of the critical words in Experiments 1 and 2 that had an /s/ in the onset of the final syllable.  
The 20 control sentences ended in the 20 control items used in Experiments 1 and 2, and the 60 filler sentences ended in the 60 filler words in Experiments 1 and 2.  
Half of all sentences were written to be predictive of the final word, and the other half were written to be unpredictive of the final word.  
Unlike previous studies using sentence or semantic predictability \citep{Kalikow1977}, unpredictive sentences were written with a range of sentence structures.
In all cases, the final words were plausible objects of lexical verbs and prepositions.  
A full list of words and their contexts can be found in the appendix. 
Aside from the sibilants in the critical and control words, the sentences contained no sibilants (/s z \textesh\ \textyogh\ \textteshlig\  \textdyoghlig/).  
The same minimal pairs for phonetic categorization as in Experiments 1 and 2 were used.

Sentences were recorded by the same male Vancouver English speaker used in Experiments 1 and 2.  
Critical sentences were recorded in pairs, with one normal production and then a production of the same sentence with the /s/ in the final word replaced with an /\textesh/.  
The speaker was instructed to produce both sentences with comparable speech rate, speech style, and prosody.

As in Experiments 1 and 2, the critical items were morphed together into an 11-step continuum using STRAIGHT \citep{Kawahara2008}; only the final word in sentence was morphed.  
The preceding words in the sentence were kept as the natural production to minimize artifacts of the morphing algorithm.  
The control and filler items were also processed and resynthesized to ensure consistent quality.  
The ambiguous point selection was based on the pretest performed for Experiment 1 and 2 exposure items.  
The ambiguous steps of the continua chosen corresponded to the 50\% cross over point in Experiment 1.

Acoustic distances between exposure tokens, categorization tokens, and their original productions were multidimensionally scaled.  In Figure~\ref{fig:exp3mds}, the original productions are separated again by the first dimension, which corresponds to the centroid frequency of the sibilant.
The categorization tokens are predictably in between the original productions, and offset in the second dimension, due to their different position in the word.
The exposure tokens for Experiment 3 fit in between the original productions and the categorization tokens.

\begin{figure*}[ht]
\caption{Multidimensional scaling of the acoustic distances between the sibilants of original productions, categorization tokens and the exposure tokens in Experiment 3.}
\label{fig:exp3mds}
\begin{center}
\includegraphics[width=\textwidth]{graphs/exp3_mds}
\end{center}
\end{figure*}

Pictures of 200 words, with 100 pictures for the final word of the sentences and 100 for distractors, were selected in two steps.  
First, a research assistant selected five images from a Google image search of the word, and then a single image representing that word was selected from amongst the five by me.  
To ensure consistent behaviour in E-Prime \citep{PsychologySoftwareTools2012}, pictures were resized to fit within a 400x400 area with a resolution of 72x72 DPI and converted to bitmap format.  
Additionally, any transparent backgrounds in the pictures were converted to plain white backgrounds.

\subsection{Pretest}

The same twenty participants that completed the lexical decision continua pre-test also completed a sentence predictability task before the phonetic categorization task described in Experiment 1. 
Participants were compensated with \$10 CAD for both tasks, and were native North American English speakers with no reported speech, language or hearing disorders. In this task, participants were presented with sentence fragments that were lacking in the final word.  
They were instructed to type in the word that came to mind when reading the fragment, and to enter any additional words that came to mind that would also complete the sentence.  
There was no time limit for entry and participants were shown an example with the fragment ``The boat sailed across the...'' and the possible completions ``bay, ocean, lake, river''.  
Responses were collected in E-Prime \citep{PsychologySoftwareTools2012}, and were sanitized by removing miscellaneous keystrokes, spell checking, and standardizing variant spellings and plural forms.

The measure used for determining rewriting of sentences was the proportion of participants that included the target word in their responses.  
For predictive sentences, the mean proportion was 0.49 (range 0-0.95) and for unpredictive sentences, the mean proportion was 0.03 (range 0-0.45).  
Predictive sentences that had target response proportions of 20\% or less were rewritten.  
The predictive sentences for \emph{auction}, \emph{brochure}, \emph{carousel}, \emph{cashier}, \emph{cockpit}, \emph{concert}, \emph{cowboy}, \emph{currency}, \emph{cursor}, \emph{cushion}, \emph{dryer}, \emph{graffiti}, and \emph{missile} were rewritten to remove any ambiguities.  

Five volunteers participated in another pretest to determine how suitable the pictures were at representing their associated word.  
All participants were native speakers of North American English, with reported corrected-to-normal vision. Participants were presented with a single image in the middle of the screen.  
Their task was to type the word that first came to mind, and any other words that described the picture equally well.  
There was no time limit and presentation of the pictures was self-paced. Responses were sanitized as above.  

Pictures were replaced if 20\% or less of the participants (1 of 5) responded with the target word and the responses were semantically unrelated to the target word. 
Five pictures were replaced, \emph{toothpick} and \emph{falafel} with clearer pictures and \emph{ukulele}, \emph{earmuff} and \emph{earplug} were replaced with \emph{rollerblader}, \emph{anchor} and \emph{bedroom}.  
All five replacements were for distractor words.

\subsection{Procedure}

As in Experiments 1 and 2, participants completed an exposure task and a categorization task.  
For the exposure task, participants heard a sentence via headphones for each trial.  
Immediately following the auditory presentation, they were presented with two pictures on the screen.  
Their task was to select the picture on the screen that corresponded to the final word in the sentence they heard.  
The order was pseudorandom with the same constraints described in Experiment 1.

Participants were assigned to one of four groups of 25 participants.  
In the exposure phase, half of the participants were exposed to a modified /s/ sound only in Predictive sentences and half were exposed to it only in Unpredictive sentences.  
Half of all participants were told that the speaker's production of ``s'' was sometimes ambiguous, and to listen carefully to ensure correct responses.  

Following the exposure task, participants completed the same categorization task described in Experiments 1 and 2.

\section{Results}

\subsection{Exposure}

Performance in the task was high, with accuracy near ceiling across all subjects (mean accuracy = 99.5\%, sd = 0.8\%).
Due to these ceiling effects, a logistic mixed-effects model of accuracy was not constructed.  
A linear mixed effects model for logarithmically-transformed reaction time was constructed with a similar structure as in Experiments 1 and 2.
Fixed effects were Trial (0-100), Trial Type (Filler, /s/, and /\textesh/), Attention (No Attention and Attention), Predictability (Unpredictive and Predictive), and their interactions.  
By-Subject and by-Word random effect structure was as maximal as permitted by the data, with by-Subject random slopes for Trial, Trial Type, Predictability, and their interactions and by-Word random slopes for Attention, Predictability, and their interaction. 
Trial Type was coded using treatment (dummy) coding, with Filler as the reference level. 
Deviance contrast coding was used for Predictability (Unpredictive = 0.5, Predictive = -0.5) and Attention (No attention = 0.5, Attention = -0.5).

\begin{figure*}[!ht]
\centering
\caption{Within-subject mean reaction time in the exposure phase of Experiment 3, separated out by Trial Type (Filler, /s/, and /\textesh/). Error bars represent 95\% confidence intervals.}
\label{fig:exp3exposert}
\begin{center}
\includegraphics[width=0.95\textwidth]{graphs/exp3_exprt}
\end{center}
\end{figure*}

A significant effect was found for Trial ($\beta = -0.20, SE = 0.01, t = -11.0$), indicating that reaction time became faster over the course of the experiment.
There was a significant effect for Trial Type of /\textesh/ versus Filler ($\beta = 0.19, SE = 0.09, t = 2.1$), but not for /s/ versus Filler ($\beta = 0.11, SE = 0.09, t = 1.3$), suggesting that words with /\textesh/ in them were responded to more slowly than filler words or those with a modified /s/ in them.
There was a significant interaction between Trial and Trial Type of  /s/ versus Filler ($\beta = 0.05, SE = 0.02, t = 2.4$) and between Trial and Trial Type of /\textesh/ versus Filler ($\beta = 0.05, SE = 0.02, t = 2.9$), indicating that reaction time for words with /s/ or /\textesh/ in them did not become as fast across the experiment as those for filler words.
These results are shown in Figure~\ref{fig:exp3exposert}.
Note that the y-axis has a different scale than that used in Experiments 1 and 2 for reactions times.
Participants were faster in this task than in the lexical decision task.


\subsection{Categorization}

Responses with reaction times less than 200 ms or greater than 2500 ms were excluded from analyses. 
A logistic mixed effects model was constructed with Subject and Continua as random effects and continua Step as random slopes, with 0 coded as a /\textesh/ response and 1 as a /s/ response.  Fixed effects for the model were Step, Exposure Type, Attention and their interactions, with deviance coding used for contrasts for Exposure Type (Unpredictive = 0.5, Predictive = -0.5) and Attention (No attention = 0.5, Attention = -0.5).


\begin{figure*}[!ht]
\caption{Proportion /s/ response along the 6 step continua as a function of Exposure Type and Attention in Experiment 3.  Error bars represent 95\% confidence intervals.}
\label{fig:exp3categ}
\begin{center}
\includegraphics[width=\textwidth]{graphs/exp3_categresults}
\end{center}
\end{figure*}

As in the previous experiments, there was a significant effect of the intercept ($\beta = 0.52, SE = 0.20, z = 2.6, p < 0.01$) and of Step ($\beta = -2.49, SE = 0.19, z = -12.7, p < 0.01$).
Exposure Type ($\beta = 0.23, SE = 0.23, z = 0.97, p = 0.33$), Attention ($\beta = 0.30, SE = 0.21, z = 1.4, p = 0.15$), and their interaction ($\beta = 0.38, SE = 0.44, z = 0.9, p = 0.39$) are all not significant, despite the visible differences in Figure~\ref{fig:exp3categ}.
In Figure~\ref{fig:exp3categ}, there appears to be a similar interaction pattern as was seen for Experiment 1 (Figure~\ref{fig:exp1categ}).
The means for the center steps in the Unpredictive condition appear to be different depending on Attention, while those in the Predictive condition show no such Attention difference.
As will be shown later, the lack of an effect is likely due a lack of statistical power, suggesting that the difference between the Exposure Type conditions is a smaller than the crucial effect in Experiment 1.

\begin{figure*}[!ht]
\caption{Proportion /s/ response along the 6 step continua as a function of Exposure Type and Attention in Experiment 3 and the word-medial condition of Experiment 1.  Error bars represent 95\% confidence intervals.}
\label{fig:exp23categ}
\begin{center}
\includegraphics[width=\textwidth]{graphs/exp23_categresults}
\end{center}
\end{figure*}


As an additional comparison, the data from this experiment was combined with the subset of participants in Experiment 1 who were exposed to the same set of words (the word-medial condition).  
Exposure Type was recoded as a three-level factor, using treatment (dummy) contrast coding, with the Experiment 1 exposure (Isolation) as the reference level. 
An identically specified logistic mixed effects model was fit to this set data as to the initial data.  
In this model, there was a significant effect of Attention ($\beta = 0.74, SE = 0.32, z = 2.2, p = 0.02$), such that participants in Attention conditions were less likely to categorize the continua steps as /s/.  
Exposure Type had a marginal effect of Predictive compared to Isolation ($\beta = -0.43, SE = 0.23, z = -1.9, p = 0.05$), indicating that participants in the Predictive condition were less likely categorize the continua as /s/ overall as compared to participants from Experiment 2. 
Step interacted with both Unpredictive as compared to Isolation ($\beta = -0.42, SE = 0.17, z = -2.4, p = 0.01$) and Predictive as compared to Isolation ($\beta = -0.32, SE = 0.14, z = -2.2, p = 0.02$).
These interactions indicate that the categorization functions for sentential stimuli had a sharper crossover than the Isolation. 
As shown in Figure~\ref{fig:exp23categ}, the endpoints (Steps 5 and 6) for the sentential conditions are wholly overlapping with the control categorization for those steps.
While participants in the Unpredictive condition showed a shifted category boundary, the perceptual learning affected less of the continua than for participants in the Isolation condition.

An additional model was run with the reference level for Exposure Type as Predictive to check whether participants in the Predictive condition showed perceptual learning effects at all.
In the model with Predictive as reference, the intercept is no longer significant ($\beta = 0.44, SE = 0.28, z = 1.5, p = 0.12$), indicating perceptual learning was not robustly present in participants in the Predictive condition.  
The difference between the Predictive condition and the Isolation condition remains ($\beta = 0.77, SE = 0.32, z = 2.4, p = 0.01$), and, as above, the difference between Predictive and Unpredictive is not significant ($\beta = 0.42, SE = 0.31, z = 1.3, p = 0.17$).
These results indicate participants in the Predictive condition showed no perceptual learning effect, and participants in the Unpredictive condition were in between Predictive and Isolation, but not significantly different from either.  
Increasing the statistical power would be necessary to separate the conditions out further.


\section{Discussion}

The key finding of the current experiment is that modified categories embedded in words in meaningful sentences produce less perceptual learning than words in isolation.  
Particularly, as the predictability of the context increases, the amount of perceptual learning decreases.  
In fact, participants exposed to a modified category only in predictive words had a similar boundary as those in the control experiment who had no exposure to a modified /s/ category.
This pattern of results aligns the most with the extension to Kraljic and colleagues' argument is that perceptual learning is a last resort.
If there is any way to attribute the acoustic atypicality to either linguistic or other sources of variation, no perceptual learning occurs \citep{Kraljic2008,Kraljic2008a}.
In the current experiment, semantic predictability appears to be a linguistic source of variation and shows identical effects as a more local source like consonant cluster coarticulation.

The prediction of a simple predictive coding model \citep{Clark2013} were not borne out.
Rather than increased expectations enhancing error signals, the conditions with increased expectations showed no perceptual learning at all.
How can we reconcile then the predictive coding model and the findings of the current experiment?
One way, certainly, is to incorporate the reliability argument of Kraljic and colleagues.
Bayesian approaches capture uncertainty quite well, so the unreliable tokens, such as those in the high predictability sentences, would have greater uncertainty associated with them.
Another possibility is that perceptual learning did occur, but it was not generalized to the test items.
Participants could have learned from their exposure how the speaker produces /s/ in high predictability contexts, but the context of words in isolation was too different from the exposure context.
Put another way, the participants could have learned how the speaker reduces his /s/ category, but not how the speaker normally produces it.

However, if semantic predictability functions in an identical way as consonant cluster coarticulation, listeners would not perceptual learning effects even if they were tested on a continuum in a high predictability sentence.
In \citet{Kraljic2008a}, listeners exposed to an ambiguous /s/ in the context of /str/ and then tested on a continuum from /astri/ to /a\textesh tri/ showed no perceptual learning effects.
Participants who were exposed to ambiguous /s/ intervocalically showed perceptual learning on both /asi/-/a\textesh i/ and /astri/-/a\textesh tri/ continua.
In this case, there is no exposure-specificity effects, so participants do not even learn that the speaker produces a more /\textesh/-like /s/ in that context.
Any abstract encoding process accounts for and removes the variability associated with the context, leaving the unmodified perceptual category.
A similar pattern is likely to be seen with high predictability exposure.

One question raised by this finding is whether any and all variation can be attributed to these contextual factors.
For instance, if this experiment had used the ambiguity threshold of Experiment 2 instead of Experiment 1, would a different pattern of results emerge?
If high predictability only resulted in broadening of perceptual categories, participants in the Predictive condition should show nearly as much perceptual learning as the current participants in the Unpredictive condition.
Increasing the atypicality of the category would likely lead to reduced perceptual learning for future participants in the Unpredictive category, mirroring the effects between Experiments 1 and 2.

As a final point in this discussion, the distribution of individuals' perceptual learning effects differs across conditions. 
Figure~\ref{fig:exp13xoverdist} shows the distribution of crossover points of each subject in Experiment 3 and participants in the condition of Experiment 1 that use the same exposure words.  
Crossover points are where along the continua the participant switches their perception from primarily /s/ to primarily /\textesh/.
Participants in the Predictive/No Attention condition have the most unique distributional pattern.
In this condition, the distribution of crossover points is fairly constrained, with a narrow interquartile range, but with many outliers.
This distribution is more peaky with long skirts to either side.
For other conditions, the distributions are captured well by the boxplots, with relatively large interquartile ranges.
These distributions are more broad, but narrower skirts.
Participants in the Predictive/No Attention could potentially be more separable into discrete groups than the other conditions where it may be more continuous.


\begin{figure*}[!ht]
\centering
\caption{Distribution of crossover points for each participant across comparable exposure tokens in Experiments 1 and 3.}
\label{fig:exp13xoverdist}
\begin{center}
\includegraphics[width=0.9\textwidth]{graphs/exp13_xoverdist}
\end{center}
\end{figure*}

One possible reason for these more discrete groups could have to do with cognitive load.
Under lower cognitive load conditions, participants in perception-oriented tasks show greater perceptual sensitivity.
In this experiment, the task is comprehension-oriented, so lower cognitive load could have distributed attentional resources to the comprehension task or to aspects of the signal.
Participants with better attention-switching control might devote those resources to perception, while those with worse attention-switching control might not, revealing a relationship as was found in \citet{Scharenborg2013}.



